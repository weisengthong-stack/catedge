{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "363b2bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial Rating Information Extraction Tool\n",
      "==================================================\n",
      "üìÅ Looking for documents in: /Users/macbookair/Downloads/Rationale\n",
      "ü§ñ Using model: llama3.1\n",
      "üíæ Output file: extracted_ratings_extended.json\n",
      "\n",
      "Found 28 documents to process:\n",
      "  - Mydin_Rationale_final (Dec 2016).pdf\n",
      "  - Mydin_Rationale (Dec 2019).pdf\n",
      "  - Bank Muamalat (April 2010 Rationale).pdf\n",
      "  - Bank Muamalat_ June 2019.pdf\n",
      "  - Mydin Rationale_Dec 2014.pdf\n",
      "  - AEON_Rationale (Apr 2018).pdf\n",
      "  - Bank Muamalat rationale (May 2016).pdf\n",
      "  - AEON_Rationale (final).pdf\n",
      "  - Mydin (Jan 2013).pdf\n",
      "  - Sample Report 5.pdf\n",
      "  - Sample Report 4.pdf\n",
      "  - Mydin Rationale (Dec 2017).pdf\n",
      "  - Sample Report 1.pdf\n",
      "  - Sample Report 3.pdf\n",
      "  - Bank Muamalat rationale (June 2012).pdf\n",
      "  - Sample Report 2.pdf\n",
      "  - Mydin - Dec 2018 (Final).pdf\n",
      "  - Mydin_Rationale_Dec2015.pdf\n",
      "  - Bank Muamalat (May 2011 Rationale) Final Rating.pdf\n",
      "  - Bank Muamalat (March 2009).pdf\n",
      "  - AEON (M) Rationale (2020) - Final.pdf\n",
      "  - Mydin - Rationale (final rating)_Nov 2011.pdf\n",
      "  - Bank Muamalat_Rationale_Aug 2013 (final).pdf\n",
      "  - Bank Muamalat rationale (July 2014).pdf\n",
      "  - AEON_Rationale (Apr 2017).pdf\n",
      "  - Bank Muamalat rationale 2018_final.pdf\n",
      "  - Bank Muamalat rationale (July 2015).pdf\n",
      "  - Mydin Rationale (Jan 2014).pdf\n",
      "\n",
      "[1/28] Processing: Mydin_Rationale_final (Dec 2016).pdf\n",
      "Processing Mydin_Rationale_final (Dec 2016).pdf...\n",
      "‚úì Successfully extracted information from Mydin_Rationale_final (Dec 2016).pdf\n",
      "\n",
      "[2/28] Processing: Mydin_Rationale (Dec 2019).pdf\n",
      "Processing Mydin_Rationale (Dec 2019).pdf...\n",
      "‚úì Successfully extracted information from Mydin_Rationale (Dec 2019).pdf\n",
      "\n",
      "[3/28] Processing: Bank Muamalat (April 2010 Rationale).pdf\n",
      "Processing Bank Muamalat (April 2010 Rationale).pdf...\n",
      "‚úì Successfully extracted information from Bank Muamalat (April 2010 Rationale).pdf\n",
      "\n",
      "[4/28] Processing: Bank Muamalat_ June 2019.pdf\n",
      "Processing Bank Muamalat_ June 2019.pdf...\n",
      "‚úì Successfully extracted information from Bank Muamalat_ June 2019.pdf\n",
      "\n",
      "[5/28] Processing: Mydin Rationale_Dec 2014.pdf\n",
      "Processing Mydin Rationale_Dec 2014.pdf...\n",
      "‚úì Successfully extracted information from Mydin Rationale_Dec 2014.pdf\n",
      "\n",
      "[6/28] Processing: AEON_Rationale (Apr 2018).pdf\n",
      "Processing AEON_Rationale (Apr 2018).pdf...\n",
      "‚úì Successfully extracted information from AEON_Rationale (Apr 2018).pdf\n",
      "\n",
      "[7/28] Processing: Bank Muamalat rationale (May 2016).pdf\n",
      "Processing Bank Muamalat rationale (May 2016).pdf...\n",
      "‚úì Successfully extracted information from Bank Muamalat rationale (May 2016).pdf\n",
      "\n",
      "[8/28] Processing: AEON_Rationale (final).pdf\n",
      "Processing AEON_Rationale (final).pdf...\n",
      "‚úì Successfully extracted information from AEON_Rationale (final).pdf\n",
      "\n",
      "[9/28] Processing: Mydin (Jan 2013).pdf\n",
      "Processing Mydin (Jan 2013).pdf...\n",
      "‚úì Successfully extracted information from Mydin (Jan 2013).pdf\n",
      "\n",
      "[10/28] Processing: Sample Report 5.pdf\n",
      "Processing Sample Report 5.pdf...\n",
      "‚úì Successfully extracted information from Sample Report 5.pdf\n",
      "\n",
      "[11/28] Processing: Sample Report 4.pdf\n",
      "Processing Sample Report 4.pdf...\n",
      "‚úì Successfully extracted information from Sample Report 4.pdf\n",
      "\n",
      "[12/28] Processing: Mydin Rationale (Dec 2017).pdf\n",
      "Processing Mydin Rationale (Dec 2017).pdf...\n",
      "‚úì Successfully extracted information from Mydin Rationale (Dec 2017).pdf\n",
      "\n",
      "[13/28] Processing: Sample Report 1.pdf\n",
      "Processing Sample Report 1.pdf...\n",
      "‚úì Successfully extracted information from Sample Report 1.pdf\n",
      "\n",
      "[14/28] Processing: Sample Report 3.pdf\n",
      "Processing Sample Report 3.pdf...\n",
      "‚úì Successfully extracted information from Sample Report 3.pdf\n",
      "\n",
      "[15/28] Processing: Bank Muamalat rationale (June 2012).pdf\n",
      "Processing Bank Muamalat rationale (June 2012).pdf...\n",
      "‚úì Successfully extracted information from Bank Muamalat rationale (June 2012).pdf\n",
      "\n",
      "[16/28] Processing: Sample Report 2.pdf\n",
      "Processing Sample Report 2.pdf...\n",
      "‚úì Successfully extracted information from Sample Report 2.pdf\n",
      "\n",
      "[17/28] Processing: Mydin - Dec 2018 (Final).pdf\n",
      "Processing Mydin - Dec 2018 (Final).pdf...\n",
      "‚úì Successfully extracted information from Mydin - Dec 2018 (Final).pdf\n",
      "\n",
      "[18/28] Processing: Mydin_Rationale_Dec2015.pdf\n",
      "Processing Mydin_Rationale_Dec2015.pdf...\n",
      "‚úì Successfully extracted information from Mydin_Rationale_Dec2015.pdf\n",
      "\n",
      "[19/28] Processing: Bank Muamalat (May 2011 Rationale) Final Rating.pdf\n",
      "Processing Bank Muamalat (May 2011 Rationale) Final Rating.pdf...\n",
      "‚úì Successfully extracted information from Bank Muamalat (May 2011 Rationale) Final Rating.pdf\n",
      "\n",
      "[20/28] Processing: Bank Muamalat (March 2009).pdf\n",
      "Processing Bank Muamalat (March 2009).pdf...\n",
      "‚úì Successfully extracted information from Bank Muamalat (March 2009).pdf\n",
      "\n",
      "[21/28] Processing: AEON (M) Rationale (2020) - Final.pdf\n",
      "Processing AEON (M) Rationale (2020) - Final.pdf...\n",
      "‚úì Successfully extracted information from AEON (M) Rationale (2020) - Final.pdf\n",
      "\n",
      "[22/28] Processing: Mydin - Rationale (final rating)_Nov 2011.pdf\n",
      "Processing Mydin - Rationale (final rating)_Nov 2011.pdf...\n",
      "‚úì Successfully extracted information from Mydin - Rationale (final rating)_Nov 2011.pdf\n",
      "\n",
      "[23/28] Processing: Bank Muamalat_Rationale_Aug 2013 (final).pdf\n",
      "Processing Bank Muamalat_Rationale_Aug 2013 (final).pdf...\n",
      "‚úì Successfully extracted information from Bank Muamalat_Rationale_Aug 2013 (final).pdf\n",
      "\n",
      "[24/28] Processing: Bank Muamalat rationale (July 2014).pdf\n",
      "Processing Bank Muamalat rationale (July 2014).pdf...\n",
      "‚úì Successfully extracted information from Bank Muamalat rationale (July 2014).pdf\n",
      "\n",
      "[25/28] Processing: AEON_Rationale (Apr 2017).pdf\n",
      "Processing AEON_Rationale (Apr 2017).pdf...\n",
      "‚úì Successfully extracted information from AEON_Rationale (Apr 2017).pdf\n",
      "\n",
      "[26/28] Processing: Bank Muamalat rationale 2018_final.pdf\n",
      "Processing Bank Muamalat rationale 2018_final.pdf...\n",
      "‚úì Successfully extracted information from Bank Muamalat rationale 2018_final.pdf\n",
      "\n",
      "[27/28] Processing: Bank Muamalat rationale (July 2015).pdf\n",
      "Processing Bank Muamalat rationale (July 2015).pdf...\n",
      "‚úì Successfully extracted information from Bank Muamalat rationale (July 2015).pdf\n",
      "\n",
      "[28/28] Processing: Mydin Rationale (Jan 2014).pdf\n",
      "Processing Mydin Rationale (Jan 2014).pdf...\n",
      "‚úì Successfully extracted information from Mydin Rationale (Jan 2014).pdf\n",
      "\n",
      "üéâ Successfully processed 28 documents!\n",
      "\n",
      "Results saved to: extracted_ratings_extended.json\n",
      "Summary saved to: extracted_ratings_extended_summary.csv\n",
      "\n",
      "============================================================\n",
      "SAMPLE EXTRACTION RESULT:\n",
      "============================================================\n",
      "File: Mydin_Rationale_final (Dec 2016).pdf\n",
      "Company: Mydin Mohamed Holdings Berhad\n",
      "Assessment: Not mentioned in the document 2016\n",
      "Rating Action Basis: The company's financial performance and creditworthiness...\n",
      "Positive Drivers: 2 found\n",
      "Negative Drivers: 3 found\n",
      "Specific Ratings: 0 found\n",
      "============================================================\n",
      "\n",
      "üìä Summary:\n",
      "  - Documents processed: 28\n",
      "  - Results saved to: extracted_ratings_extended.json\n",
      "  - Summary CSV created: extracted_ratings_extended_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pypdf\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "OLLAMA_URL = 'http://localhost:11434/api/generate'\n",
    "MODEL_NAME = 'llama3.1'\n",
    "DOCUMENTS_FOLDER = '/Users/macbookair/Downloads/Rationale'  # Change this to your documents folder path\n",
    "OUTPUT_FILE = 'extracted_ratings_extended.json'\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize extracted text\"\"\"\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def read_document(file_path):\n",
    "    \"\"\"Read document content based on file type\"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    \n",
    "    try:\n",
    "        if file_path.suffix.lower() == '.pdf':\n",
    "            with open(file_path, 'rb') as file:\n",
    "                pdf_reader = pypdf.PdfReader(file)\n",
    "                content = \"\"\n",
    "                for page_num, page in enumerate(pdf_reader.pages):\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text.strip():\n",
    "                        content += f\"\\n--- Page {page_num + 1} ---\\n{page_text}\\n\"\n",
    "                return clean_text(content)\n",
    "        else:\n",
    "            # Handle text files\n",
    "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                content = file.read()\n",
    "                return clean_text(content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def extract_rating_information(document_content, filename):\n",
    "    \"\"\"Extract rating information using LLM\"\"\"\n",
    "    \n",
    "    extraction_prompt = f\"\"\"\n",
    "You are a financial analyst tasked with extracting specific information from rating agency documents. \n",
    "\n",
    "Analyze the following document and extract ONLY the information that is explicitly mentioned:\n",
    "\n",
    "DOCUMENT:\n",
    "{document_content}\n",
    "\n",
    "Extract the following information and format as JSON:\n",
    "\n",
    "1. Company Name: The name of the entity being rated\n",
    "2. Assessment Year and Month: When the assessment/rating was conducted or published\n",
    "3. Rating Action Basis: The primary reason or basis for the rating action\n",
    "4. Rating Drivers (Positive): Factors that support or could improve the rating\n",
    "5. Rating Drivers (Negative): Factors that constrain or could worsen the rating  \n",
    "6. Rating Triggers (Upgrade/Downgrade): Specific conditions that could lead to rating changes\n",
    "7. ESG Descriptor: Any Environmental, Social, Governance factors mentioned\n",
    "8. Related Criteria: References to rating methodologies, criteria, or frameworks used\n",
    "9. Specific Ratings: Extract exact rating levels and what they apply to\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "- If any information is not explicitly mentioned in the document, state \"Not mentioned in the document\"\n",
    "- Use precise, analytical language\n",
    "- Quote directly from the document when possible\n",
    "- Be thorough but only include information that is clearly stated\n",
    "- For the Rating Drivers, both Positive and Negative, please include more points into the JSON instead of just 1 point to avoid over-summarization\n",
    "- For Rating Triggers, both Upgrade and Downgrade, please include more points into the JSON instead of just 1 point to avoud over-summarization\n",
    "- Please do not provide information that is not in the document\n",
    "\n",
    "Output ONLY a valid JSON object in this exact format:\n",
    "\n",
    "{{\n",
    "  \"company_name\": \"\",\n",
    "  \"assessment_year\": \"\",\n",
    "  \"assessment_month\": \"\",\n",
    "  \"rating_action_basis\": \"\",\n",
    "  \"rating_drivers_positive\": [],\n",
    "  \"rating_drivers_negative\": [],\n",
    "  \"rating_triggers_upgrade\": [],\n",
    "  \"rating_triggers_downgrade\": [],\n",
    "  \"esg_descriptor\": \"\",\n",
    "  \"related_criteria\": [],\n",
    "  \"specific_ratings\": []\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\n",
    "        'model': MODEL_NAME,\n",
    "        'prompt': extraction_prompt,\n",
    "        'stream': False,\n",
    "        'options': {\n",
    "            'temperature': 0.1,  # Low temperature for consistency\n",
    "            'num_ctx': 8192,     # Large context window for long documents\n",
    "            'top_p': 0.9\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"Processing {filename}...\")\n",
    "        response = requests.post(OLLAMA_URL, headers=headers, json=data, timeout=120)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            ai_response = result.get('response', '')\n",
    "            \n",
    "            # Try to extract JSON from the response\n",
    "            try:\n",
    "                # Find JSON in the response (in case there's extra text)\n",
    "                json_start = ai_response.find('{')\n",
    "                json_end = ai_response.rfind('}') + 1\n",
    "                \n",
    "                if json_start != -1 and json_end != 0:\n",
    "                    json_str = ai_response[json_start:json_end]\n",
    "                    extracted_data = json.loads(json_str)\n",
    "                    extracted_data['source_file'] = filename\n",
    "                    extracted_data['extraction_timestamp'] = datetime.now().isoformat()\n",
    "                    return extracted_data\n",
    "                else:\n",
    "                    print(f\"No valid JSON found in response for {filename}\")\n",
    "                    return None\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON parsing error for {filename}: {str(e)}\")\n",
    "                print(f\"Raw response: {ai_response[:500]}...\")\n",
    "                return None\n",
    "                \n",
    "        else:\n",
    "            print(f\"API error for {filename}: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_documents_batch(documents_folder, supported_extensions=None):\n",
    "    \"\"\"Process all documents in a folder\"\"\"\n",
    "    \n",
    "    if supported_extensions is None:\n",
    "        supported_extensions = {'.pdf', '.txt', '.md', '.py', '.js', '.html', '.css', '.json'}\n",
    "    \n",
    "    documents_path = Path(documents_folder)\n",
    "    \n",
    "    if not documents_path.exists():\n",
    "        print(f\"Documents folder '{documents_folder}' does not exist!\")\n",
    "        print(\"Please create the folder and add your documents.\")\n",
    "        return []\n",
    "    \n",
    "    # Find all supported document files\n",
    "    document_files = []\n",
    "    for ext in supported_extensions:\n",
    "        document_files.extend(documents_path.glob(f\"*{ext}\"))\n",
    "    \n",
    "    if not document_files:\n",
    "        print(f\"No supported documents found in '{documents_folder}'\")\n",
    "        print(f\"Supported extensions: {supported_extensions}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Found {len(document_files)} documents to process:\")\n",
    "    for file in document_files:\n",
    "        print(f\"  - {file.name}\")\n",
    "    \n",
    "    extracted_results = []\n",
    "    \n",
    "    # Process each document\n",
    "    for i, doc_file in enumerate(document_files, 1):\n",
    "        print(f\"\\n[{i}/{len(document_files)}] Processing: {doc_file.name}\")\n",
    "        \n",
    "        # Read document content\n",
    "        content = read_document(doc_file)\n",
    "        if content is None:\n",
    "            print(f\"Skipping {doc_file.name} due to read error\")\n",
    "            continue\n",
    "        \n",
    "        if len(content.strip()) == 0:\n",
    "            print(f\"Skipping {doc_file.name} - empty content\")\n",
    "            continue\n",
    "        \n",
    "        # Extract information\n",
    "        extracted_info = extract_rating_information(content, doc_file.name)\n",
    "        \n",
    "        if extracted_info:\n",
    "            extracted_results.append(extracted_info)\n",
    "            print(f\"‚úì Successfully extracted information from {doc_file.name}\")\n",
    "        else:\n",
    "            print(f\"‚úó Failed to extract information from {doc_file.name}\")\n",
    "    \n",
    "    return extracted_results\n",
    "\n",
    "def save_results(results, output_file):\n",
    "    \"\"\"Save extraction results to JSON file\"\"\"\n",
    "    try:\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nResults saved to: {output_file}\")\n",
    "        \n",
    "        # Also create a summary CSV\n",
    "        if results:\n",
    "            df_data = []\n",
    "            for result in results:\n",
    "                row = {\n",
    "                    'source_file': result.get('source_file', ''),\n",
    "                    'company_name': result.get('company_name', ''),\n",
    "                    'assessment_year': result.get('assessment_year', ''),\n",
    "                    'assessment_month': result.get('assessment_month', ''),\n",
    "                    'rating_action_basis': result.get('rating_action_basis', '')[:100] + '...' if len(result.get('rating_action_basis', '')) > 100 else result.get('rating_action_basis', ''),\n",
    "                    'num_positive_drivers': len(result.get('rating_drivers_positive', [])),\n",
    "                    'num_negative_drivers': len(result.get('rating_drivers_negative', [])),\n",
    "                    'num_specific_ratings': len(result.get('specific_ratings', [])),\n",
    "                    'extraction_timestamp': result.get('extraction_timestamp', '')\n",
    "                }\n",
    "                df_data.append(row)\n",
    "            \n",
    "            df = pd.DataFrame(df_data)\n",
    "            csv_file = output_file.replace('.json', '_summary.csv')\n",
    "            df.to_csv(csv_file, index=False)\n",
    "            print(f\"Summary saved to: {csv_file}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {str(e)}\")\n",
    "\n",
    "def display_sample_result(results):\n",
    "    \"\"\"Display a sample result for verification\"\"\"\n",
    "    if results:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SAMPLE EXTRACTION RESULT:\")\n",
    "        print(\"=\"*60)\n",
    "        sample = results[0]\n",
    "        print(f\"File: {sample.get('source_file', 'Unknown')}\")\n",
    "        print(f\"Company: {sample.get('company_name', 'Not found')}\")\n",
    "        print(f\"Assessment: {sample.get('assessment_month', 'Not found')} {sample.get('assessment_year', 'Not found')}\")\n",
    "        print(f\"Rating Action Basis: {sample.get('rating_action_basis', 'Not found')[:200]}...\")\n",
    "        print(f\"Positive Drivers: {len(sample.get('rating_drivers_positive', []))} found\")\n",
    "        print(f\"Negative Drivers: {len(sample.get('rating_drivers_negative', []))} found\")\n",
    "        print(f\"Specific Ratings: {len(sample.get('specific_ratings', []))} found\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "# MAIN EXECUTION LOOP\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Financial Rating Information Extraction Tool\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check if Ollama is running\n",
    "    try:\n",
    "        test_response = requests.get('http://localhost:11434/api/tags', timeout=5)\n",
    "        if test_response.status_code != 200:\n",
    "            print(\"‚ö†Ô∏è  Warning: Ollama may not be running properly\")\n",
    "    except:\n",
    "        print(\"‚ùå Error: Cannot connect to Ollama. Make sure it's running on localhost:11434\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(f\"üìÅ Looking for documents in: {DOCUMENTS_FOLDER}\")\n",
    "    print(f\"ü§ñ Using model: {MODEL_NAME}\")\n",
    "    print(f\"üíæ Output file: {OUTPUT_FILE}\")\n",
    "    print()\n",
    "    \n",
    "    # Process all documents\n",
    "    results = process_documents_batch(DOCUMENTS_FOLDER)\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\nüéâ Successfully processed {len(results)} documents!\")\n",
    "        \n",
    "        # Save results\n",
    "        save_results(results, OUTPUT_FILE)\n",
    "        \n",
    "        # Display sample\n",
    "        display_sample_result(results)\n",
    "        \n",
    "        print(f\"\\nüìä Summary:\")\n",
    "        print(f\"  - Documents processed: {len(results)}\")\n",
    "        print(f\"  - Results saved to: {OUTPUT_FILE}\")\n",
    "        print(f\"  - Summary CSV created: {OUTPUT_FILE.replace('.json', '_summary.csv')}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n‚ùå No documents were successfully processed.\")\n",
    "        print(\"Please check:\")\n",
    "        print(\"  1. Documents exist in the specified folder\")\n",
    "        print(\"  2. Documents are in supported formats\")\n",
    "        print(\"  3. Ollama is running and accessible\")\n",
    "        print(\"  4. The model 'llama3.1' is available\")\n",
    "\n",
    "# OPTIONAL: Interactive mode for single document testing\n",
    "def test_single_document(file_path):\n",
    "    \"\"\"Test extraction on a single document\"\"\"\n",
    "    print(f\"Testing single document: {file_path}\")\n",
    "    \n",
    "    content = read_document(file_path)\n",
    "    if content:\n",
    "        result = extract_rating_information(content, Path(file_path).name)\n",
    "        if result:\n",
    "            print(json.dumps(result, indent=2))\n",
    "        else:\n",
    "            print(\"Failed to extract information\")\n",
    "    else:\n",
    "        print(\"Failed to read document\")\n",
    "\n",
    "# Uncomment the line below to test a single document:\n",
    "# test_single_document(\"./path/to/your/test/document.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c01ab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing single document: /Users/macbookair/Downloads/AEON_Rationale (Apr 2017).pdf\n",
      "Processing AEON_Rationale (Apr 2017).pdf...\n",
      "{\n",
      "  \"company_name\": \"AEON CO. BHD.\",\n",
      "  \"assessment_year\": \"2017\",\n",
      "  \"assessment_month\": \"Not mentioned in the document\",\n",
      "  \"rating_action_basis\": \"The company's financial performance and debt levels\",\n",
      "  \"rating_drivers_positive\": [\n",
      "    \"Strong revenue growth\"\n",
      "  ],\n",
      "  \"rating_drivers_negative\": [\n",
      "    \"High debt levels\",\n",
      "    \"Weak profitability\"\n",
      "  ],\n",
      "  \"rating_triggers_upgrade\": [\n",
      "    \"Improvement in profitability\",\n",
      "    \"Reduction in debt levels\"\n",
      "  ],\n",
      "  \"rating_triggers_downgrade\": [\n",
      "    \"Further deterioration in financial performance\",\n",
      "    \"Increase in debt levels\"\n",
      "  ],\n",
      "  \"esg_descriptor\": \"Not mentioned in the document\",\n",
      "  \"related_criteria\": [\n",
      "    \"RAM Rating methodologies and criteria\"\n",
      "  ],\n",
      "  \"specific_ratings\": [\n",
      "    {\n",
      "      \"rating_level\": \"BBB- (Stable)\",\n",
      "      \"applicable_to\": \"Long-term issuer rating\"\n",
      "    },\n",
      "    {\n",
      "      \"rating_level\": \"A3 (Stable)\",\n",
      "      \"applicable_to\": \"Short-term commercial paper rating\"\n",
      "    }\n",
      "  ],\n",
      "  \"source_file\": \"AEON_Rationale (Apr 2017).pdf\",\n",
      "  \"extraction_timestamp\": \"2025-07-15T21:27:37.290324\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "test_single_document('/Users/macbookair/Downloads/AEON_Rationale (Apr 2017).pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e0736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
